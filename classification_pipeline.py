import time

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from tqdm import tqdm

from emotions_multi_class_classifier import run_selected_models
from nlp_project.utils.helper_methods import HelperMethods
from nlp_project.utils.logger import Logger


class ClassificationPipeline:
    helper_methods: HelperMethods = HelperMethods()

    def __init__(self):
        self.logger: Logger = Logger(class_name=self.__class__.__name__)

    def load_and_prepare_dataset(self, path, label_col, prefix):
        df = pd.read_csv(path)
        df["text"] = df["text"].astype(str)

        # Normalize and prefix label
        df[label_col] = df[label_col].fillna("").astype(str)
        df = df[df[label_col] != ""]
        df[label_col] = df[label_col].apply(lambda x: [f"{prefix}_{x.strip()}"] if isinstance(x, str) else [])

        # Explode and regroup to get multilabels
        df = df.groupby("text")[label_col].sum().reset_index()

        # Binarize
        mlb = MultiLabelBinarizer()
        labels = mlb.fit_transform(df[label_col])
        label_names = mlb.classes_

        self.logger.info(f"{prefix} dataset: {len(df)} examples, {len(label_names)} labels")

        return df["text"].tolist(), labels, label_names

    def prepare_bert_embeddings(self, texts, batch_size=32):
        return self.helper_methods.get_bert_embeddings(texts, batch_size=batch_size)

    def process_and_run_all_models(self):
        self.logger.info(f"RUNNING THE PIPELINE")
        datasets = [
            # # TRIGGERS
            ("labeled_outputs/labeled_triggers_keywords.csv", "triggers_label_keywords", "triggers_keywords"),
            ("labeled_outputs/labeled_triggers_sentiment.csv", "triggers_label_sentiment", "triggers_sentiment"),

            # THEMES
            ("labeled_outputs/labeled_themes_keywords.csv", "themes_label_keywords", "themes_keywords"),
            ("labeled_outputs/labeled_themes_sentiment.csv", "themes_label_sentiment", "themes_sentiment"),

            # SYMPTOMS
            ("labeled_outputs/labeled_symptoms_keywords.csv", "symptoms_label_keywords", "symptoms_keywords"),
            ("labeled_outputs/labeled_symptoms_sentiment.csv", "symptoms_label_sentiment", "symptoms_sentiment"),
        ]

        progress = tqdm(datasets, desc="Running datasets", unit="dataset")

        for path, label_col, prefix in progress:
            start_time = time.time()

            texts, labels, label_names = self.load_and_prepare_dataset(path, label_col, prefix)

            # Split
            train_texts, test_texts, train_labels, test_labels = train_test_split(
                texts, labels, test_size=0.2, random_state=42
            )

            # Get BERT embeddings
            self.logger.info(f"ðŸ”„ Generating BERT embeddings for {prefix}...")
            X_train_bert = self.prepare_bert_embeddings(train_texts)
            X_test_bert = self.prepare_bert_embeddings(test_texts)

            # TFIDF (optional - skip if only using BERT)
            vectorizer = TfidfVectorizer(max_features=5000, stop_words="english")
            X_train_tfidf = vectorizer.fit_transform(train_texts)
            X_test_tfidf = vectorizer.transform(test_texts)

            # Set globals (you can modularize this if you want isolation)
            globals()["X_train_bert"] = X_train_bert
            globals()["X_test_bert"] = X_test_bert
            globals()["X_train_tfidf"] = X_train_tfidf
            globals()["X_test_tfidf"] = X_test_tfidf
            globals()["train_texts"] = train_texts
            globals()["test_texts"] = test_texts
            globals()["train_labels"] = np.array(train_labels, dtype=np.float32)
            globals()["test_labels"] = np.array(test_labels, dtype=np.float32)

            models_to_run = [
                "logreg_tfidf",
                "svm_tfidf",
                "logreg_bert",
                "svm_bert",
                "mlp_bert",
                "cnn_bert",
                "lstm_bert",
                "bert_finetune"
            ]

            self.logger.info(f"Running models for {prefix.upper()}")
            run_selected_models(models_to_run, X_train_tfidf=X_train_tfidf,
                                X_test_tfidf=X_test_tfidf,
                                X_train_bert=X_train_bert,
                                X_test_bert=X_test_bert,
                                train_texts=train_texts,
                                test_texts=test_texts,
                                train_labels=train_labels,
                                test_labels=test_labels,
                                label_names=label_names,
                                label_prefix=prefix)

            # Show time per dataset
            elapsed = time.time() - start_time
            self.logger.info(f"âœ… Finished {prefix} in {elapsed / 60:.1f} minutes")
